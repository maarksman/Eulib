{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2b138e20fd90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x2b138e134ed0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from datetime import datetime\n",
    "\n",
    "# Define functions to parse txt files containing itmes, stores, customers, and transactions\n",
    "def parseStore(s):\n",
    "    l=s.split('|')\n",
    "    return Row(store_num=int(l[0]), \n",
    "               store_name=l[1],               \n",
    "               store_zone=l[2],\n",
    "               store_city=l[3], \n",
    "               store_state=l[4], \n",
    "               store_type=int(l[5]))\n",
    "\n",
    "def parseItem(s):\n",
    "    l=s.split('|')\n",
    "    return Row(item_number=int(l[0]), \n",
    "               dept_categ_class=l[1],               \n",
    "               item_des=l[2],\n",
    "               item_unt_qty=float(l[3]), \n",
    "               size_unit_desc=l[4], \n",
    "               brand_code=l[5], \n",
    "               dept_num=int(l[6]), \n",
    "               dept_name=l[7], \n",
    "               categ_num=int(l[8]), \n",
    "               categ_name=l[9], \n",
    "               class_num=int(l[10]),\n",
    "               class_name=l[11])\n",
    "\n",
    "def parseCustomer(s):\n",
    "    l=s.split('|')\n",
    "    return Row(hshld_acct=int(l[0]),\n",
    "               birth_yr_head_hh=l[1],\n",
    "               hh_income=l[2],\n",
    "               hh_size=l[3],\n",
    "               adult_count=l[4],\n",
    "               child_count=l[5],\n",
    "               birth_yr_oldest=l[6],\n",
    "               birth_yr_youngest=l[7],\n",
    "               bad_address=l[8],\n",
    "               privacy=l[9],\n",
    "               application_date=datetime.strptime(l[10],'%Y-%m-%d'),\n",
    "               wine_email_sent=int(l[11]),\n",
    "               wine_email_open=int(l[12]),\n",
    "               wine_email_click=int(l[13]))\n",
    "\n",
    "def parsePostrans(s):\n",
    "    l=s.split('|')\n",
    "    return Row(hshld_acct=int(l[0]),\n",
    "               acct_num=int(l[1]),\n",
    "               trans_num=int(l[2]),\n",
    "               trans_date=datetime.strptime(l[3],'%Y-%m-%d'),\n",
    "               store_num=int(l[4]),\n",
    "               item_number=int(l[5]),\n",
    "               dept_categ_class=l[6],\n",
    "               unit_count=int(l[7]),\n",
    "               net_sales=float(l[8]),\n",
    "               gross_sales=float(l[9]),\n",
    "               manuf_coupon=float(l[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path='/public/tbiswas2/csc261/spark/wegmans/'\n",
    "\n",
    "storeDF=spark.createDataFrame(sc.textFile(path+'wegmans_store_master.txt').map(lambda x: parseStore(x)))\n",
    "customerDF=spark.createDataFrame(sc.textFile(path+'wegmans_customer_master.txt').map(lambda x: parseCustomer(x)))\n",
    "itemDF=spark.createDataFrame(sc.textFile(path+'wegmans_item_master.txt').map(lambda x: parseItem(x)))\n",
    "postransDF=spark.createDataFrame(sc.textFile(path+'partial_transaction.dat').map(lambda x: parsePostrans(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+---------+-----------+----------+----------+\n",
      "|   store_city|          store_name|store_num|store_state|store_type|store_zone|\n",
      "+-------------+--------------------+---------+-----------+----------+----------+\n",
      "|        DEPEW|   WEGMANS DICK ROAD|       80|         NY|         1|   BUFFALO|\n",
      "|      AMHERST|WEGMANS ALBERTA D...|       82|         NY|         1|   BUFFALO|\n",
      "|WILLIAMSVILLE|WEGMANS SHERIDAN ...|       83|         NY|         1|   BUFFALO|\n",
      "|      BUFFALO|    WEGMANS MCKINLEY|       84|         NY|         1|   BUFFALO|\n",
      "|      AMHERST|WEGMANS NIAGARA F...|       86|         NY|         1|   BUFFALO|\n",
      "+-------------+--------------------+---------+-----------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------+--------------------+-----------+----------------+---------------+-----------------+-----------+---------+-------+----------+-------+----------------+---------------+---------------+\n",
      "|adult_count|    application_date|bad_address|birth_yr_head_hh|birth_yr_oldest|birth_yr_youngest|child_count|hh_income|hh_size|hshld_acct|privacy|wine_email_click|wine_email_open|wine_email_sent|\n",
      "+-----------+--------------------+-----------+----------------+---------------+-----------------+-----------+---------+-------+----------+-------+----------------+---------------+---------------+\n",
      "|          2|2012-10-21 00:00:...|          N|            1981|              0|                0|          0|    62500|      2|       559|      N|               0|              0|              0|\n",
      "|          0|2014-02-06 00:00:...|          N|               0|              0|                0|          0|        0|      0|       868|      N|               0|              0|              0|\n",
      "|          2|2012-09-25 00:00:...|          N|            1983|              0|                0|          1|   112500|      3|      1030|      Y|               0|              0|              0|\n",
      "|          1|2012-09-27 00:00:...|          N|            1979|              0|                0|          0|    35000|      1|      4270|      N|               0|              0|              0|\n",
      "|          0|2014-02-07 00:00:...|          N|               0|              0|                0|          0|        0|      0|      4580|      N|               0|              0|              0|\n",
      "+-----------+--------------------+-----------+----------------+---------------+-----------------+-----------+---------+-------+----------+-------+----------------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+--------------------+---------+--------------------+---------+----------------+---------+--------+--------------------+-----------+------------+--------------+\n",
      "|brand_code|          categ_name|categ_num|          class_name|class_num|dept_categ_class|dept_name|dept_num|            item_des|item_number|item_unt_qty|size_unit_desc|\n",
      "+----------+--------------------+---------+--------------------+---------+----------------+---------+--------+--------------------+-----------+------------+--------------+\n",
      "|      WEGF|WEGMANS WHITE BREADS|        1|  WEGMAN WHITE BREAD|        1|          010101| BAKESHOP|       1|      WG GIANT BREAD|      19190|        22.0|            OZ|\n",
      "|      WEGF|WEGMANS WHITE BREADS|        1|  WEGMAN WHITE BREAD|        1|          010101| BAKESHOP|       1|  WG HOMESTYLE BREAD|      60505|        16.0|            OZ|\n",
      "|      STRM| VENDOR WHITE BREADS|        2|STROEHMANN WHITE ...|       30|          010230| BAKESHOP|       1|       STRH KING BRD|      58944|        22.0|            OZ|\n",
      "|      STRM| VENDOR WHITE BREADS|        2|STROEHMANN WHITE ...|       30|          010230| BAKESHOP|       1|    STRH RANCH BREAD|      82707|        20.0|            OZ|\n",
      "|      STRM| VENDOR WHITE BREADS|        2|STROEHMANN WHITE ...|       30|          010230| BAKESHOP|       1|STRH SML FAMILY W...|     142071|        13.0|            OZ|\n",
      "+----------+--------------------+---------+--------------------+---------+----------------+---------+--------+--------------------+-----------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+----------------+-----------+----------+-----------+------------+---------+---------+--------------------+---------+----------+\n",
      "|acct_num|dept_categ_class|gross_sales|hshld_acct|item_number|manuf_coupon|net_sales|store_num|          trans_date|trans_num|unit_count|\n",
      "+--------+----------------+-----------+----------+-----------+------------+---------+---------+--------------------+---------+----------+\n",
      "|     559|          010327|       1.99|       559|      16705|         0.0|     1.99|       64|2013-06-01 00:00:...|   174758|         1|\n",
      "|     559|          010640|       2.29|       559|      85189|         0.0|     2.29|       64|2013-06-01 00:00:...|   174758|         1|\n",
      "|     559|          021410|       5.99|       559|      24159|         0.0|     5.99|       64|2013-06-01 00:00:...|   174758|         1|\n",
      "|     559|          022036|       3.49|       559|      33378|         0.0|     3.49|       64|2013-06-01 00:00:...|   174758|         1|\n",
      "|     559|          022036|       5.99|       559|      33261|         0.0|     5.99|       64|2013-06-01 00:00:...|   174758|         1|\n",
      "+--------+----------------+-----------+----------+-----------+------------+---------+---------+--------------------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "storeDF.show(5)\n",
    "customerDF.show(5)\n",
    "itemDF.show(5)\n",
    "postransDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemDF.select('dept_num').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|store_state|count|\n",
      "+-----------+-----+\n",
      "|         NJ|   12|\n",
      "|         VA|    6|\n",
      "|         MD|    8|\n",
      "|         PA|   16|\n",
      "|         NY|   50|\n",
      "|         MA|    2|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "storeDF.groupBy('store_state').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storeDF.filter(storeDF.store_state == 'NY').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 35298)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/software/python/2.7.10/b1/lib/python2.7/SocketServer.py\", line 295, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/software/python/2.7.10/b1/lib/python2.7/SocketServer.py\", line 321, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/software/python/2.7.10/b1/lib/python2.7/SocketServer.py\", line 334, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/software/python/2.7.10/b1/lib/python2.7/SocketServer.py\", line 655, in __init__\n",
      "    self.handle()\n",
      "  File \"/software/spark/2.0.0/b1/python/pyspark/accumulators.py\", line 235, in handle\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/software/spark/2.0.0/b1/python/pyspark/serializers.py\", line 545, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:44895)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f6fb8206417e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpostransDD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpostransDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trans_date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmaxdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpostransDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmindate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpostransDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmindate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mmax\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    971\u001b[0m         \"\"\"\n\u001b[0;32m    972\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mreduce\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    803\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    774\u001b[0m         \"\"\"\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m             \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    777\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/pyspark/traceback_utils.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, tb)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetCallSite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m         return_value = get_return_value(\n\u001b[0;32m    933\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m    691\u001b[0m          \u001b[1;32mif\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \"\"\"\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    645\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_close\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_property\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m             self.ssl_context)\n\u001b[1;32m--> 647\u001b[1;33m         \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    782\u001b[0m                 \u001b[1;34m\"server ({0}:{1})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:44895)"
     ]
    }
   ],
   "source": [
    "postransDD = postransDF.select(\"trans_date\").rdd\n",
    "maxdate = postransDD.max()[0]\n",
    "mindate = postransDD.min()[0]\n",
    "print(maxdate)\n",
    "print(mindate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 50160)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/software/python/2.7.10/b1/lib/python2.7/SocketServer.py\", line 295, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/software/python/2.7.10/b1/lib/python2.7/SocketServer.py\", line 321, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/software/python/2.7.10/b1/lib/python2.7/SocketServer.py\", line 334, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/software/python/2.7.10/b1/lib/python2.7/SocketServer.py\", line 655, in __init__\n",
      "    self.handle()\n",
      "  File \"/software/spark/2.0.0/b1/python/pyspark/accumulators.py\", line 235, in handle\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/software/spark/2.0.0/b1/python/pyspark/serializers.py\", line 545, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:40965)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d872b4e629fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnewtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpostransRestrict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstoreRestrict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstoreRestrict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstore_num\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpostransRestrict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstore_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnewtable1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnewtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trans_num'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnewtable1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36mcount\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m         return_value = get_return_value(\n\u001b[0;32m    933\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Exception while sending command.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m                 logging.exception(\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m    691\u001b[0m          \u001b[1;32mif\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \"\"\"\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    645\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_close\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_property\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m             self.ssl_context)\n\u001b[1;32m--> 647\u001b[1;33m         \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/software/spark/2.0.0/b1/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    782\u001b[0m                 \u001b[1;34m\"server ({0}:{1})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:40965)"
     ]
    }
   ],
   "source": [
    "storeRestrict = storeDF.filter(storeDF.store_name == 'WEGMANS MARKETPLACE')\n",
    "postransRestrict = postransDF.select('store_num','trans_num')\n",
    "newtable = postransRestrict.join(storeRestrict, storeRestrict.store_num == postransRestrict.store_num)\n",
    "newtable1 = newtable.select('trans_num')\n",
    "newtable1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tff=postransDF.agg({\"unit_count\": \"avg\"})\n",
    "tff.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg\n",
    "tf1=postransDF.agg(avg(col(\"unit_count\")))\n",
    "tf1.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "postransDF.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemDF.filter(itemDF['class_name'] == 'WHOLE MILK').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "milktableDF = itemDF.filter(itemDF['class_name'] == 'WHOLE MILK')\n",
    "milkfilterDF = milktableDF.select('class_name', 'item_number')\n",
    "milkjoinDF = postransDF.join(milkfilterDF, milkfilterDF.item_number == postransDF.item_number)\n",
    "milkhouse = milkjoinDF.select('hshld_acct','unit_count')\n",
    "milksumDF = milkhouse.groupBy('hshld_acct').agg(F.sum('unit_count').alias('Units_sold'))\n",
    "maxmilkDD = milksumDF.select('Units_sold').rdd\n",
    "maxmilkval = maxmilkDD.max()[0]\n",
    "#print(maxmilkval)\n",
    "milksumordered = milksumDF.orderBy(milksumDF.Units_sold.desc())\n",
    "maxhousemilkDF = milksumDF.filter(milksumDF['Units_sold'] == maxmilkval)\n",
    "maxmilkhshldDF = maxhousemilkDF.select('hshld_acct')\n",
    "maxmilkhshldnum = maxmilkhshldDF.rdd.max()[0]\n",
    "milkbuyertuple = customerDF.filter(customerDF['hshld_acct'] == maxmilkhshldnum).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itemDFLB = itemDF.filter(itemDF.size_unit_desc == 'LB')\n",
    "itemRDD = itemDFLB.select(\"item_unt_qty\").rdd\n",
    "maxweight = itemRDD.max()[0]\n",
    "itemDFLBmax = itemDFLB.filter(itemDFLB.item_unt_qty == maxweight)\n",
    "itemDFLBmax.sort('item_unt_qty',ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Query 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q10=postransDF.groupBy(\"trans_num\").sum(\"unit_count\")\n",
    "q10.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Query 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "postransDF.join(customerDF, 'hshld_acct') \\\n",
    "    .filter(customerDF.hshld_acct>0) \\\n",
    "    .groupBy('store_num') \\\n",
    "    .agg(F.avg('hh_size').alias('average household size')) \\\n",
    "    .join(storeDF, 'store_num') \\\n",
    "    .select('store_name','average household size') \\\n",
    "    .sort('average household size',ascending=False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Find the top three (3) stores with the highest number of customers. Display the name of the stores and the\n",
    "##number of customers.\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "distinctposDF = postransDF.select('hshld_acct', 'store_num').distinct()\n",
    "custcountbystoreDF = distinctposDF.groupBy('store_num').count().sort('count', ascending=False)\n",
    "#custcountbystoreDF.show()\n",
    "storecustDF = storeDF.join(custcountbystoreDF, storeDF.store_num == custcountbystoreDF.store_num).select('store_name', 'count')\n",
    "storecustDF.sort('count', ascending=False).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "postrans12 = postransDF.select('store_num','net_sales','trans_num','trans_date')\n",
    "salescount = postransDF.groupBy(['store_num','trans_date'])\\\n",
    "            .agg(F.sum('net_sales').alias('summation'))\n",
    "saleStore = salescount.groupBy('store_num').max('summation')\n",
    "saleStore.join(storeDF,'store_num').select('store_name','max(summation)')\\\n",
    "            .sort('max(summation)',ascending=False)\\\n",
    "            .show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "transsalesitemsDF = postransDF.select('trans_num', 'net_sales','item_number')\n",
    "transsalesDF = postransDF.select('trans_num','net_sales')\n",
    "sumsalestransDF = transsalesDF.groupBy('trans_num').agg(F.sum('net_sales').alias('total_net_sales'))\n",
    "transitemDF = transsalesitemsDF\n",
    "sumssaletransDD = sumsalestransDF.sort('total_net_sales',ascending=False).rdd\n",
    "ss11 = sumssaletransDD.zipWithIndex().filter(lambda (r,i): i < 3).map(lambda x: x[0])\n",
    "dataframenew = spark.createDataFrame(ss11).select('trans_num')\n",
    "rddnew1 = postransDF.join(dataframenew,'trans_num').select('trans_num','item_number').rdd\n",
    "rddnew2 = rddnew1.map(lambda x: (x[0],[ x[1] ])).reduceByKey(lambda x,y: x+y)\n",
    "rddnew2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (spark)",
   "language": "python",
   "name": "python-2.7.10-b1-spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
