{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = {u'a',u'b',u'c',u'd',u'e',u'f',u'g',u'h',u'i',u'j',u'k',u'l',u'm',u'n',u'o',u'p',\n",
    "           u'q',u'r',u's',u't',u'u',u'v',u'w',u'x',u'y',u'z'}\n",
    "\n",
    "eyre=sc.textFile('/public/tbiswas2/csc261/spark/bronte-jane-eyre.txt')\n",
    "words=eyre.flatMap(lambda x: x.split())\n",
    "letters=words.flatMap(lambda x: list(x))\n",
    "letters1 = letters.map(lambda x: (x.lower(),1))\n",
    "letterCountX=letters1.reduceByKey(lambda v1, v2: v1+v2).filter(lambda x : x[0] in alphabet)\n",
    "letterCountX=letterCountX.sortByKey()\n",
    "\n",
    "letterCountL = letterCountX.collect()\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "letterCountList = letterCountL\n",
    "zippedletterCount = zip(*letterCountList)\n",
    " \n",
    "letters = zippedletterCount[0]\n",
    "y_pos = np.arange(len(letters))\n",
    "letterCount = zippedletterCount[1]\n",
    " \n",
    "plt.bar(y_pos, letterCount, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, letters)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Letter Frequency')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "storeDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "storeRestrict = storeDF.filter(storeDF.store_name == 'WEGMANS MARKETPLACE')\n",
    "postransRestrict = postransDF.select('store_num','trans_num')\n",
    "newtable = postransRestrict.join(storeRestrict, storeRestrict.store_num == postransRestrict.store_num)\n",
    "newtable1 = newtable.select('trans_num')\n",
    "newtable1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itemDFLB = itemDF.filter(itemDF.size_unit_desc == 'LB')\n",
    "itemRDD = itemDFLB.select(\"item_unt_qty\").rdd\n",
    "maxweight = itemRDD.max()[0]\n",
    "itemDFLBmax = itemDFLB.filter(itemDFLB.item_unt_qty == maxweight)\n",
    "itemDFLBmax.sort('item_unt_qty',ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "postrans12 = postransDF.select('store_num','net_sales','trans_num','trans_date')\n",
    "salescount = postransDF.groupBy(['store_num','trans_date'])\\\n",
    "            .agg(F.sum('net_sales').alias('summation'))\n",
    "saleStore = salescount.groupBy('store_num').max('summation')\n",
    "saleStore.join(storeDF,'store_num').select('store_name','max(summation)')\\\n",
    "            .sort('max(summation)',ascending=False)\\\n",
    "            .show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "transsalesitemsDF = postransDF.select('trans_num', 'net_sales','item_number')\n",
    "transsalesDF = postransDF.select('trans_num','net_sales')\n",
    "sumsalestransDF = transsalesDF.groupBy('trans_num').agg(F.sum('net_sales').alias('total_net_sales'))\n",
    "transitemDF = transsalesitemsDF\n",
    "sumssaletransDD = sumsalestransDF.sort('total_net_sales',ascending=False).rdd\n",
    "ss11 = sumssaletransDD.zipWithIndex().filter(lambda (r,i): i < 3).map(lambda x: x[0])\n",
    "dataframenew = spark.createDataFrame(ss11).select('trans_num')\n",
    "rddnew1 = postransDF.join(dataframenew,'trans_num').select('trans_num','item_number').rdd\n",
    "rddnew2 = rddnew1.map(lambda x: (x[0],[ x[1] ])).reduceByKey(lambda x,y: x+y)\n",
    "rddnew2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (spark)",
   "language": "python",
   "name": "python-2.7.10-b1-spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
